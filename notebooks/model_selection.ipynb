{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb68cfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "883130de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 82011 entries, 0 to 82010\n",
      "Data columns (total 42 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   place_id              82011 non-null  float64\n",
      " 1   hour                  82011 non-null  int64  \n",
      " 2   item_count            82011 non-null  float64\n",
      " 3   order_count           82011 non-null  int64  \n",
      " 4   total_revenue         82011 non-null  float64\n",
      " 5   avg_order_value       82011 non-null  float64\n",
      " 6   avg_items_per_order   82011 non-null  float64\n",
      " 7   datetime              82011 non-null  str    \n",
      " 8   day_of_week           82011 non-null  int64  \n",
      " 9   month                 82011 non-null  int64  \n",
      " 10  week_of_year          82011 non-null  int64  \n",
      " 11  type_id               80433 non-null  float64\n",
      " 12  waiting_time          82009 non-null  float64\n",
      " 13  rating                82009 non-null  float64\n",
      " 14  delivery              82009 non-null  float64\n",
      " 15  accepting_orders      82009 non-null  float64\n",
      " 16  longitude             82011 non-null  float64\n",
      " 17  latitude              82011 non-null  float64\n",
      " 18  total_campaigns       82011 non-null  float64\n",
      " 19  avg_discount          82011 non-null  float64\n",
      " 20  prev_hour_items       82011 non-null  float64\n",
      " 21  prev_day_items        82011 non-null  float64\n",
      " 22  prev_week_items       82011 non-null  float64\n",
      " 23  prev_month_items      82011 non-null  float64\n",
      " 24  rolling_7d_avg_items  82011 non-null  float64\n",
      " 25  temperature_2m        82011 non-null  float64\n",
      " 26  relative_humidity_2m  82011 non-null  int64  \n",
      " 27  precipitation         82011 non-null  float64\n",
      " 28  rain                  82011 non-null  float64\n",
      " 29  snowfall              82011 non-null  float64\n",
      " 30  weather_code          82011 non-null  int64  \n",
      " 31  cloud_cover           82011 non-null  int64  \n",
      " 32  wind_speed_10m        82011 non-null  float64\n",
      " 33  is_rainy              82011 non-null  int64  \n",
      " 34  is_snowy              82011 non-null  int64  \n",
      " 35  is_cold               82011 non-null  int64  \n",
      " 36  is_hot                82011 non-null  int64  \n",
      " 37  is_cloudy             82011 non-null  int64  \n",
      " 38  is_windy              82011 non-null  int64  \n",
      " 39  good_weather          82011 non-null  int64  \n",
      " 40  weather_severity      82011 non-null  int64  \n",
      " 41  is_holiday            82011 non-null  bool   \n",
      "dtypes: bool(1), float64(24), int64(16), str(1)\n",
      "memory usage: 25.7 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/processed/combined_features.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77d508b",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9cf23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values before handling:\n",
      "type_id             1578\n",
      "waiting_time           2\n",
      "rating                 2\n",
      "delivery               2\n",
      "accepting_orders       2\n",
      "dtype: int64\n",
      "\n",
      "Null values after handling:\n",
      "0 total nulls remaining\n",
      "        place_id  hour  day_of_week  month  week_of_year  type_id  \\\n",
      "0        59813.0    14            1      6            23   1335.0   \n",
      "1        59813.0    15            1      6            23   1335.0   \n",
      "2        59813.0    14            4      6            23   1335.0   \n",
      "3        59813.0    15            4      6            23   1335.0   \n",
      "4        59813.0    16            4      6            23   1335.0   \n",
      "...          ...   ...          ...    ...           ...      ...   \n",
      "82006  1547577.0    16            4      2             7  12191.0   \n",
      "82007  1547577.0    17            4      2             7  12191.0   \n",
      "82008  1547577.0    18            4      2             7  12191.0   \n",
      "82009  1617411.0    16            4      2             7  12191.0   \n",
      "82010  1617411.0    17            4      2             7  12191.0   \n",
      "\n",
      "       waiting_time  rating  delivery  accepting_orders  ...  wind_speed_10m  \\\n",
      "0              25.0   198.0       0.0               1.0  ...            11.9   \n",
      "1              25.0   198.0       0.0               1.0  ...            11.9   \n",
      "2              25.0   198.0       0.0               1.0  ...            14.0   \n",
      "3              25.0   198.0       0.0               1.0  ...            12.5   \n",
      "4              25.0   198.0       0.0               1.0  ...            13.4   \n",
      "...             ...     ...       ...               ...  ...             ...   \n",
      "82006          15.0     0.0       1.0               1.0  ...             7.2   \n",
      "82007          15.0     0.0       1.0               1.0  ...             7.6   \n",
      "82008          15.0     0.0       1.0               1.0  ...             8.0   \n",
      "82009          15.0     0.0       0.0               1.0  ...            22.0   \n",
      "82010          15.0     0.0       0.0               1.0  ...            21.9   \n",
      "\n",
      "       is_rainy  is_snowy  is_cold  is_hot  is_cloudy  is_windy  good_weather  \\\n",
      "0             0         0        0       0          0         0             1   \n",
      "1             0         0        0       0          0         0             1   \n",
      "2             0         0        0       0          1         0             1   \n",
      "3             0         0        0       0          1         0             1   \n",
      "4             0         0        0       0          0         0             1   \n",
      "...         ...       ...      ...     ...        ...       ...           ...   \n",
      "82006         0         0        1       0          1         0             0   \n",
      "82007         0         0        1       0          1         0             0   \n",
      "82008         0         0        1       0          1         0             0   \n",
      "82009         1         0        0       0          1         0             0   \n",
      "82010         1         0        0       0          1         0             0   \n",
      "\n",
      "       weather_severity  is_holiday  \n",
      "0                     0           0  \n",
      "1                     0           0  \n",
      "2                     0           0  \n",
      "3                     0           0  \n",
      "4                     0           0  \n",
      "...                 ...         ...  \n",
      "82006                 1           0  \n",
      "82007                 1           0  \n",
      "82008                 1           0  \n",
      "82009                 2           0  \n",
      "82010                 2           0  \n",
      "\n",
      "[82011 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "target_features = ['item_count', 'order_count']\n",
    "useless_features = ['total_revenue', 'avg_order_value', 'avg_items_per_order']\n",
    "x, y = df.drop(target_features, axis=1), df[target_features]\n",
    "x = x.drop(useless_features, axis=1)\n",
    "\n",
    "# Drop datetime column (it's already encoded into temporal features)\n",
    "x = x.drop('datetime', axis=1)\n",
    "\n",
    "# Handle null values\n",
    "print(f\"Null values before handling:\\n{x.isnull().sum()[x.isnull().sum() > 0]}\\n\")\n",
    "\n",
    "# Strategy 1: Drop latitude/longitude (40% missing - too much to impute reliably)\n",
    "x = x.drop(['longitude', 'latitude'], axis=1)\n",
    "\n",
    "# Strategy 2: Fill remaining nulls with appropriate values\n",
    "# For categorical: use mode or create 'unknown' category\n",
    "x['type_id'] = x['type_id'].fillna(-1)  # -1 indicates missing type\n",
    "\n",
    "# For numerical restaurant features: use median (robust to outliers)\n",
    "x['waiting_time'] = x['waiting_time'].fillna(x['waiting_time'].median())\n",
    "x['rating'] = x['rating'].fillna(x['rating'].median())\n",
    "x['delivery'] = x['delivery'].fillna(0)  # Binary: assume no delivery if missing\n",
    "x['accepting_orders'] = x['accepting_orders'].fillna(0)  # Binary: assume not accepting if missing\n",
    "\n",
    "print(f\"Null values after handling:\\n{x.isnull().sum().sum()} total nulls remaining\")\n",
    "\n",
    "# Convert all object/string dtypes to avoid serialization issues with multiprocessing\n",
    "x['place_id'] = x['place_id'].astype('float64')\n",
    "x['type_id'] = x['type_id'].astype('float64')\n",
    "x['is_holiday'] = x['is_holiday'].astype('int')\n",
    "\n",
    "# Fix column index dtype issue - convert to regular Python strings\n",
    "x.columns = x.columns.astype(str)\n",
    "y.columns = y.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b16d83ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the time series data into train and test sets\n",
    "train_size = int(len(x) * 0.8)\n",
    "x_train, x_test = x[:train_size], x[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7a7ef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_features = [\n",
    "    # Restaurant features (varying ranges)\n",
    "    'waiting_time',           # Minutes (0-60+)\n",
    "    'rating',                 # 0-5 scale\n",
    "    'avg_discount',           # Percentage (0-100)\n",
    "    \n",
    "    # Lag/historical features (count data, large range)\n",
    "    'prev_hour_items',        # Can be 0-1000+\n",
    "    'prev_day_items',         # Can be 0-10000+\n",
    "    'prev_week_items',        # Can be 0-50000+\n",
    "    'prev_month_items',       # Can be 0-200000+\n",
    "    'rolling_7d_avg_items',   # Average counts\n",
    "    \n",
    "    # Weather features (different units/scales)\n",
    "    'temperature_2m',         # Celsius (-10 to 40+)\n",
    "    'relative_humidity_2m',   # Percentage (0-100)\n",
    "    'precipitation',          # mm (0-50+)\n",
    "    'rain',                   # mm (0-50+)\n",
    "    'snowfall',               # cm (0-50+)\n",
    "    'cloud_cover',            # Percentage (0-100)\n",
    "    'wind_speed_10m',         # km/h (0-100+)\n",
    "    'weather_severity'        # Encoded scale\n",
    "]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('sclaler', StandardScaler(), scale_features)],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89b0d27",
   "metadata": {},
   "source": [
    "## Linear Regression (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf6ae627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Set Performance:\n",
      "\n",
      "item_count:\n",
      "  RMSE: 448.7509\n",
      "  MAE: 5.1911\n",
      "  R2: -3.8057\n",
      "\n",
      "order_count:\n",
      "  RMSE: 50.4729\n",
      "  MAE: 2.8188\n",
      "  R2: -0.4895\n",
      "\n",
      "Test Set Performance:\n",
      "\n",
      "item_count:\n",
      "  RMSE: 71.6337\n",
      "  MAE: 4.4789\n",
      "  R2: -0.0304\n",
      "\n",
      "order_count:\n",
      "  RMSE: 19.5025\n",
      "  MAE: 2.6600\n",
      "  R2: 0.1409\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', MultiOutputRegressor(LinearRegression()))\n",
    "])\n",
    "\n",
    "linear_model = TransformedTargetRegressor(\n",
    "    regressor=pipeline,\n",
    "    func=np.log1p,\n",
    "    inverse_func=np.expm1\n",
    ")\n",
    "\n",
    "linear_model.fit(x_train, y_train)\n",
    "y_train_pred_linear = linear_model.predict(x_train)\n",
    "y_test_pred_linear = linear_model.predict(x_test)\n",
    "\n",
    "# Evaluate on training set\n",
    "print(\"\\nTraining Set Performance:\")\n",
    "for i, target in enumerate(target_features):\n",
    "    print(f\"\\n{target}:\")\n",
    "    print(f\"  RMSE: {mean_squared_error(y_train.iloc[:, i], y_train_pred_linear[:, i]):.4f}\")\n",
    "    print(f\"  MAE: {mean_absolute_error(y_train.iloc[:, i], y_train_pred_linear[:, i]):.4f}\")\n",
    "    print(f\"  R2: {r2_score(y_train.iloc[:, i], y_train_pred_linear[:, i]):.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\nTest Set Performance:\")\n",
    "for i, target in enumerate(target_features):\n",
    "    print(f\"\\n{target}:\")\n",
    "    print(f\"  RMSE: {mean_squared_error(y_test.iloc[:, i], y_test_pred_linear[:, i]):.4f}\")\n",
    "    print(f\"  MAE: {mean_absolute_error(y_test.iloc[:, i], y_test_pred_linear[:, i]):.4f}\")\n",
    "    print(f\"  R2: {r2_score(y_test.iloc[:, i], y_test_pred_linear[:, i]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e80884",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc65b45",
   "metadata": {},
   "source": [
    "### Initial Run (default hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f3ded2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Training Set Performance:\n",
      "\n",
      "item_count:\n",
      "  RMSE: 10.3647\n",
      "  MAE: 1.6907\n",
      "  R2: 0.8890\n",
      "\n",
      "order_count:\n",
      "  RMSE: 2.8177\n",
      "  MAE: 0.8865\n",
      "  R2: 0.9168\n",
      "\n",
      "Random Forest Test Set Performance:\n",
      "\n",
      "item_count:\n",
      "  RMSE: 44.8262\n",
      "  MAE: 4.1621\n",
      "  R2: 0.3552\n",
      "\n",
      "order_count:\n",
      "  RMSE: 17.1104\n",
      "  MAE: 2.6727\n",
      "  R2: 0.2463\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', MultiOutputRegressor(RandomForestRegressor(n_jobs=-1, random_state=42)))\n",
    "])\n",
    "\n",
    "random_forest_model = TransformedTargetRegressor(\n",
    "    regressor=pipeline,\n",
    "    func=np.log1p,\n",
    "    inverse_func=np.expm1\n",
    ")\n",
    "\n",
    "random_forest_model.fit(x_train, y_train)\n",
    "y_train_pred_rf = random_forest_model.predict(x_train)\n",
    "y_test_pred_rf = random_forest_model.predict(x_test)\n",
    "\n",
    "# Evaluate on training set\n",
    "print(\"\\nRandom Forest Training Set Performance:\")\n",
    "for i, target in enumerate(target_features):\n",
    "    print(f\"\\n{target}:\")\n",
    "    print(f\"  RMSE: {mean_squared_error(y_train.iloc[:, i], y_train_pred_rf[:, i]):.4f}\")\n",
    "    print(f\"  MAE: {mean_absolute_error(y_train.iloc[:, i], y_train_pred_rf[:, i]):.4f}\")\n",
    "    print(f\"  R2: {r2_score(y_train.iloc[:, i], y_train_pred_rf[:, i]):.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\nRandom Forest Test Set Performance:\")\n",
    "for i, target in enumerate(target_features):\n",
    "    print(f\"\\n{target}:\")\n",
    "    print(f\"  RMSE: {mean_squared_error(y_test.iloc[:, i], y_test_pred_rf[:, i]):.4f}\")\n",
    "    print(f\"  MAE: {mean_absolute_error(y_test.iloc[:, i], y_test_pred_rf[:, i]):.4f}\")\n",
    "    print(f\"  R2: {r2_score(y_test.iloc[:, i], y_test_pred_rf[:, i]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68902de",
   "metadata": {},
   "source": [
    "### Enhanced Run (tuned hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae55fd5",
   "metadata": {},
   "source": [
    "#### First Stage: structure + regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f51a1721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best parameters found: {'regressor__model__estimator__max_depth': 10, 'regressor__model__estimator__max_features': 0.5, 'regressor__model__estimator__min_samples_leaf': 4}\n",
      "\n",
      "Random Forest Training Set Performance:\n",
      "\n",
      "item_count:\n",
      "  RMSE: 45.8082\n",
      "  MAE: 4.1017\n",
      "  R2: 0.5094\n",
      "\n",
      "order_count:\n",
      "  RMSE: 13.9589\n",
      "  MAE: 2.2475\n",
      "  R2: 0.5881\n",
      "\n",
      "Random Forest Test Set Performance:\n",
      "\n",
      "item_count:\n",
      "  RMSE: 45.0272\n",
      "  MAE: 4.1390\n",
      "  R2: 0.3523\n",
      "\n",
      "order_count:\n",
      "  RMSE: 16.8069\n",
      "  MAE: 2.6346\n",
      "  R2: 0.2596\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', MultiOutputRegressor(RandomForestRegressor(n_jobs=-1, random_state=42)))\n",
    "])\n",
    "\n",
    "random_forest_model = TransformedTargetRegressor(\n",
    "    regressor=pipeline,\n",
    "    func=np.log1p,\n",
    "    inverse_func=np.expm1\n",
    ")\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    estimator=random_forest_model,\n",
    "    param_grid = {\n",
    "        'regressor__model__estimator__max_depth': [10, 20],\n",
    "        'regressor__model__estimator__min_samples_leaf': [2, 4],\n",
    "        'regressor__model__estimator__max_features': ['sqrt', 0.5],\n",
    "    },\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=TimeSeriesSplit(n_splits=5),\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "gs.fit(x_train, y_train)\n",
    "print(f\"Best parameters found: {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a790d987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Best parameters found: {'regressor__model__estimator__max_depth': 15, 'regressor__model__estimator__max_features': 0.5, 'regressor__model__estimator__min_samples_leaf': 5}\n"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(\n",
    "    estimator=random_forest_model,\n",
    "    param_grid = {\n",
    "        'regressor__model__estimator__max_depth': [5, 10, 15],\n",
    "        'regressor__model__estimator__min_samples_leaf': [3, 4, 5],\n",
    "        'regressor__model__estimator__max_features': [0.5, 'log2'],\n",
    "    },\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=TimeSeriesSplit(n_splits=5),\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "gs.fit(x_train, y_train)\n",
    "print(f\"Best parameters found: {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f56f204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best parameters found: {'regressor__model__estimator__max_depth': 10, 'regressor__model__estimator__min_samples_leaf': 7}\n"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(\n",
    "    estimator=random_forest_model,\n",
    "    param_grid = {\n",
    "        'regressor__model__estimator__max_depth': [10, 15, 20, 25],\n",
    "        'regressor__model__estimator__min_samples_leaf': [4, 5, 6, 7]\n",
    "    },\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=TimeSeriesSplit(n_splits=5),\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "gs.fit(x_train, y_train)\n",
    "print(f\"Best parameters found: {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b1a1ab",
   "metadata": {},
   "source": [
    "#### Second: stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a29d7507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best parameters found: {'regressor__model__estimator__bootstrap': True, 'regressor__model__estimator__n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "gs2 = GridSearchCV(\n",
    "    estimator=random_forest_model,\n",
    "    param_grid = {\n",
    "        'regressor__model__estimator__n_estimators': [100, 200, 400],\n",
    "        'regressor__model__estimator__bootstrap': [True, False],\n",
    "    },\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=TimeSeriesSplit(n_splits=5),\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "gs2.fit(x_train, y_train)\n",
    "print(f\"Best parameters found: {gs2.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "103d9171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best parameters found: {'regressor__model__estimator__bootstrap': True, 'regressor__model__estimator__n_estimators': 600}\n"
     ]
    }
   ],
   "source": [
    "gs2 = GridSearchCV(\n",
    "    estimator=random_forest_model,\n",
    "    param_grid = {\n",
    "        'regressor__model__estimator__n_estimators': [400, 500, 600],\n",
    "        'regressor__model__estimator__bootstrap': [True, False],\n",
    "    },\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=TimeSeriesSplit(n_splits=5),\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "gs2.fit(x_train, y_train)\n",
    "print(f\"Best parameters found: {gs2.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d921d9bc",
   "metadata": {},
   "source": [
    "### Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "192a1d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Training Set Performance:\n",
      "\n",
      "item_count:\n",
      "  RMSE: 42.1696\n",
      "  MAE: 3.8778\n",
      "  R2: 0.5484\n",
      "\n",
      "order_count:\n",
      "  RMSE: 12.8647\n",
      "  MAE: 2.1209\n",
      "  R2: 0.6203\n",
      "\n",
      "Random Forest Test Set Performance:\n",
      "\n",
      "item_count:\n",
      "  RMSE: 43.9525\n",
      "  MAE: 4.1044\n",
      "  R2: 0.3678\n",
      "\n",
      "order_count:\n",
      "  RMSE: 16.7480\n",
      "  MAE: 2.6255\n",
      "  R2: 0.2622\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', MultiOutputRegressor(RandomForestRegressor(\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        max_depth=12,\n",
    "        min_samples_leaf=7,\n",
    "        max_features=0.5,\n",
    "        n_estimators=600,\n",
    "        bootstrap=True\n",
    "    )))\n",
    "])\n",
    "\n",
    "best_model = TransformedTargetRegressor(\n",
    "    regressor=pipeline,\n",
    "    func=np.log1p,\n",
    "    inverse_func=np.expm1\n",
    ")\n",
    "\n",
    "best_model.fit(x_train, y_train)\n",
    "\n",
    "y_train_pred_best = best_model.predict(x_train)\n",
    "y_test_pred_best = best_model.predict(x_test)\n",
    "\n",
    "# Evaluate on training set\n",
    "print(\"\\nRandom Forest Training Set Performance:\")\n",
    "for i, target in enumerate(target_features):\n",
    "    print(f\"\\n{target}:\")\n",
    "    print(f\"  RMSE: {mean_squared_error(y_train.iloc[:, i], y_train_pred_best[:, i]):.4f}\")\n",
    "    print(f\"  MAE: {mean_absolute_error(y_train.iloc[:, i], y_train_pred_best[:, i]):.4f}\")\n",
    "    print(f\"  R2: {r2_score(y_train.iloc[:, i], y_train_pred_best[:, i]):.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\nRandom Forest Test Set Performance:\")\n",
    "for i, target in enumerate(target_features):\n",
    "    print(f\"\\n{target}:\")\n",
    "    print(f\"  RMSE: {mean_squared_error(y_test.iloc[:, i], y_test_pred_best[:, i]):.4f}\")\n",
    "    print(f\"  MAE: {mean_absolute_error(y_test.iloc[:, i], y_test_pred_best[:, i]):.4f}\")\n",
    "    print(f\"  R2: {r2_score(y_test.iloc[:, i], y_test_pred_best[:, i]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84e0eb1",
   "metadata": {},
   "source": [
    "## Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "17889a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/models/rf_model_metadata.json']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = {\n",
    "    'python_version': sys.version,\n",
    "    'sklearn_version': sys.modules['sklearn'].__version__,\n",
    "    'numpy_version': sys.modules['numpy'].__version__,\n",
    "    'model_type': 'RandomForestRegressor',\n",
    "    'preprocessing': {\n",
    "        'scaled_features': scale_features,\n",
    "        'imputation_strategies': {\n",
    "            'type_id': 'mode (-1 for unknown)',\n",
    "            'waiting_time': 'median',\n",
    "            'rating': 'median',\n",
    "            'delivery': 'fill 0',\n",
    "            'accepting_orders': 'fill 0'\n",
    "        }\n",
    "    },\n",
    "    'hyperparameters': {\n",
    "        'max_depth': 12,\n",
    "        'min_samples_leaf': 7,\n",
    "        'max_features': 0.5,\n",
    "        'n_estimators': 600,\n",
    "        'bootstrap': True\n",
    "    },\n",
    "    'training_size': len(x_train),\n",
    "    'test_size': len(x_test)\n",
    "}\n",
    "\n",
    "joblib.dump(best_model, '../data/models/rf_model.joblib')\n",
    "joblib.dump(metadata, '../data/models/rf_model_metadata.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2ec8a5",
   "metadata": {},
   "source": [
    "## DONE!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deloitte",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
