{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb68cfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "883130de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 82011 entries, 0 to 82010\n",
      "Data columns (total 42 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   place_id              82011 non-null  float64\n",
      " 1   hour                  82011 non-null  int64  \n",
      " 2   item_count            82011 non-null  float64\n",
      " 3   order_count           82011 non-null  int64  \n",
      " 4   total_revenue         82011 non-null  float64\n",
      " 5   avg_order_value       82011 non-null  float64\n",
      " 6   avg_items_per_order   82011 non-null  float64\n",
      " 7   datetime              82011 non-null  str    \n",
      " 8   day_of_week           82011 non-null  int64  \n",
      " 9   month                 82011 non-null  int64  \n",
      " 10  week_of_year          82011 non-null  int64  \n",
      " 11  type_id               80433 non-null  float64\n",
      " 12  waiting_time          82009 non-null  float64\n",
      " 13  rating                82009 non-null  float64\n",
      " 14  delivery              82009 non-null  float64\n",
      " 15  accepting_orders      82009 non-null  float64\n",
      " 16  longitude             82011 non-null  float64\n",
      " 17  latitude              82011 non-null  float64\n",
      " 18  total_campaigns       82011 non-null  float64\n",
      " 19  avg_discount          82011 non-null  float64\n",
      " 20  prev_hour_items       82011 non-null  float64\n",
      " 21  prev_day_items        82011 non-null  float64\n",
      " 22  prev_week_items       82011 non-null  float64\n",
      " 23  prev_month_items      82011 non-null  float64\n",
      " 24  rolling_7d_avg_items  82011 non-null  float64\n",
      " 25  temperature_2m        82011 non-null  float64\n",
      " 26  relative_humidity_2m  82011 non-null  int64  \n",
      " 27  precipitation         82011 non-null  float64\n",
      " 28  rain                  82011 non-null  float64\n",
      " 29  snowfall              82011 non-null  float64\n",
      " 30  weather_code          82011 non-null  int64  \n",
      " 31  cloud_cover           82011 non-null  int64  \n",
      " 32  wind_speed_10m        82011 non-null  float64\n",
      " 33  is_rainy              82011 non-null  int64  \n",
      " 34  is_snowy              82011 non-null  int64  \n",
      " 35  is_cold               82011 non-null  int64  \n",
      " 36  is_hot                82011 non-null  int64  \n",
      " 37  is_cloudy             82011 non-null  int64  \n",
      " 38  is_windy              82011 non-null  int64  \n",
      " 39  good_weather          82011 non-null  int64  \n",
      " 40  weather_severity      82011 non-null  int64  \n",
      " 41  is_holiday            82011 non-null  bool   \n",
      "dtypes: bool(1), float64(24), int64(16), str(1)\n",
      "memory usage: 25.7 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/processed/combined_features.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77d508b",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec9cf23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values before handling:\n",
      "type_id             1578\n",
      "waiting_time           2\n",
      "rating                 2\n",
      "delivery               2\n",
      "accepting_orders       2\n",
      "dtype: int64\n",
      "\n",
      "Null values after handling:\n",
      "0 total nulls remaining\n"
     ]
    }
   ],
   "source": [
    "target_features = ['item_count', 'order_count']\n",
    "useless_features = ['total_revenue', 'avg_order_value', 'avg_items_per_order']\n",
    "x, y = df.drop(target_features, axis=1), df[target_features]\n",
    "x = x.drop(useless_features, axis=1)\n",
    "\n",
    "# Drop datetime column (it's already encoded into temporal features)\n",
    "x = x.drop('datetime', axis=1)\n",
    "\n",
    "# Handle null values\n",
    "print(f\"Null values before handling:\\n{x.isnull().sum()[x.isnull().sum() > 0]}\\n\")\n",
    "\n",
    "# Strategy 1: Drop latitude/longitude (40% missing - too much to impute reliably)\n",
    "x = x.drop(['longitude', 'latitude'], axis=1)\n",
    "\n",
    "# Strategy 2: Fill remaining nulls with appropriate values\n",
    "# For categorical: use mode or create 'unknown' category\n",
    "x['type_id'] = x['type_id'].fillna(-1)  # -1 indicates missing type\n",
    "\n",
    "# For numerical restaurant features: use median (robust to outliers)\n",
    "x['waiting_time'] = x['waiting_time'].fillna(x['waiting_time'].median())\n",
    "x['rating'] = x['rating'].fillna(x['rating'].median())\n",
    "x['delivery'] = x['delivery'].fillna(0)  # Binary: assume no delivery if missing\n",
    "x['accepting_orders'] = x['accepting_orders'].fillna(0)  # Binary: assume not accepting if missing\n",
    "\n",
    "print(f\"Null values after handling:\\n{x.isnull().sum().sum()} total nulls remaining\")\n",
    "\n",
    "# Convert all object/string dtypes to avoid serialization issues with multiprocessing\n",
    "x['place_id'] = x['place_id'].astype('float64')\n",
    "x['type_id'] = x['type_id'].astype('float64')\n",
    "x['is_holiday'] = x['is_holiday'].astype('int')\n",
    "\n",
    "# Fix column index dtype issue - convert to regular Python strings\n",
    "x.columns = x.columns.astype(str)\n",
    "y.columns = y.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b16d83ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the time series data into train and test sets\n",
    "train_size = int(len(x) * 0.8)\n",
    "x_train, x_test = x[:train_size], x[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c7a7ef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_features = [\n",
    "    # Restaurant features (varying ranges)\n",
    "    'waiting_time',           # Minutes (0-60+)\n",
    "    'rating',                 # 0-5 scale\n",
    "    'avg_discount',           # Percentage (0-100)\n",
    "    \n",
    "    # Lag/historical features (count data, large range)\n",
    "    'prev_hour_items',        # Can be 0-1000+\n",
    "    'prev_day_items',         # Can be 0-10000+\n",
    "    'prev_week_items',        # Can be 0-50000+\n",
    "    'prev_month_items',       # Can be 0-200000+\n",
    "    'rolling_7d_avg_items',   # Average counts\n",
    "    \n",
    "    # Weather features (different units/scales)\n",
    "    'temperature_2m',         # Celsius (-10 to 40+)\n",
    "    'relative_humidity_2m',   # Percentage (0-100)\n",
    "    'precipitation',          # mm (0-50+)\n",
    "    'rain',                   # mm (0-50+)\n",
    "    'snowfall',               # cm (0-50+)\n",
    "    'cloud_cover',            # Percentage (0-100)\n",
    "    'wind_speed_10m',         # km/h (0-100+)\n",
    "    'weather_severity'        # Encoded scale\n",
    "]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('sclaler', StandardScaler(), scale_features)],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89b0d27",
   "metadata": {},
   "source": [
    "## Linear Regression (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bf6ae627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Set Performance:\n",
      "\n",
      "item_count:\n",
      "  RMSE: 446.0370\n",
      "  MAE: 5.1902\n",
      "  R2: -3.7767\n",
      "\n",
      "order_count:\n",
      "  RMSE: 50.4362\n",
      "  MAE: 2.8187\n",
      "  R2: -0.4884\n",
      "\n",
      "Test Set Performance:\n",
      "\n",
      "item_count:\n",
      "  RMSE: 71.6137\n",
      "  MAE: 4.4791\n",
      "  R2: -0.0301\n",
      "\n",
      "order_count:\n",
      "  RMSE: 19.5026\n",
      "  MAE: 2.6600\n",
      "  R2: 0.1409\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', MultiOutputRegressor(LinearRegression()))\n",
    "])\n",
    "\n",
    "linear_model = TransformedTargetRegressor(\n",
    "    regressor=pipeline,\n",
    "    func=np.log1p,\n",
    "    inverse_func=np.expm1\n",
    ")\n",
    "\n",
    "linear_model.fit(x_train, y_train)\n",
    "y_train_pred_linear = linear_model.predict(x_train)\n",
    "y_test_pred_linear = linear_model.predict(x_test)\n",
    "\n",
    "# Evaluate on training set\n",
    "print(\"\\nTraining Set Performance:\")\n",
    "for i, target in enumerate(target_features):\n",
    "    print(f\"\\n{target}:\")\n",
    "    print(f\"  RMSE: {mean_squared_error(y_train.iloc[:, i], y_train_pred_linear[:, i]):.4f}\")\n",
    "    print(f\"  MAE: {mean_absolute_error(y_train.iloc[:, i], y_train_pred_linear[:, i]):.4f}\")\n",
    "    print(f\"  R2: {r2_score(y_train.iloc[:, i], y_train_pred_linear[:, i]):.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\nTest Set Performance:\")\n",
    "for i, target in enumerate(target_features):\n",
    "    print(f\"\\n{target}:\")\n",
    "    print(f\"  RMSE: {mean_squared_error(y_test.iloc[:, i], y_test_pred_linear[:, i]):.4f}\")\n",
    "    print(f\"  MAE: {mean_absolute_error(y_test.iloc[:, i], y_test_pred_linear[:, i]):.4f}\")\n",
    "    print(f\"  R2: {r2_score(y_test.iloc[:, i], y_test_pred_linear[:, i]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e80884",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc65b45",
   "metadata": {},
   "source": [
    "### Initial Run (default hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5f3ded2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Training Set Performance:\n",
      "\n",
      "item_count:\n",
      "  RMSE: 10.3632\n",
      "  MAE: 1.6907\n",
      "  R2: 0.8890\n",
      "\n",
      "order_count:\n",
      "  RMSE: 2.8046\n",
      "  MAE: 0.8859\n",
      "  R2: 0.9172\n",
      "\n",
      "Random Forest Test Set Performance:\n",
      "\n",
      "item_count:\n",
      "  RMSE: 44.9750\n",
      "  MAE: 4.1670\n",
      "  R2: 0.3531\n",
      "\n",
      "order_count:\n",
      "  RMSE: 17.1261\n",
      "  MAE: 2.6756\n",
      "  R2: 0.2456\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', MultiOutputRegressor(RandomForestRegressor(n_jobs=-1, random_state=42)))\n",
    "])\n",
    "\n",
    "random_forest_model = TransformedTargetRegressor(\n",
    "    regressor=pipeline,\n",
    "    func=np.log1p,\n",
    "    inverse_func=np.expm1\n",
    ")\n",
    "\n",
    "random_forest_model.fit(x_train, y_train)\n",
    "y_train_pred_rf = random_forest_model.predict(x_train)\n",
    "y_test_pred_rf = random_forest_model.predict(x_test)\n",
    "\n",
    "# Evaluate on training set\n",
    "print(\"\\nRandom Forest Training Set Performance:\")\n",
    "for i, target in enumerate(target_features):\n",
    "    print(f\"\\n{target}:\")\n",
    "    print(f\"  RMSE: {mean_squared_error(y_train.iloc[:, i], y_train_pred_rf[:, i]):.4f}\")\n",
    "    print(f\"  MAE: {mean_absolute_error(y_train.iloc[:, i], y_train_pred_rf[:, i]):.4f}\")\n",
    "    print(f\"  R2: {r2_score(y_train.iloc[:, i], y_train_pred_rf[:, i]):.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\nRandom Forest Test Set Performance:\")\n",
    "for i, target in enumerate(target_features):\n",
    "    print(f\"\\n{target}:\")\n",
    "    print(f\"  RMSE: {mean_squared_error(y_test.iloc[:, i], y_test_pred_rf[:, i]):.4f}\")\n",
    "    print(f\"  MAE: {mean_absolute_error(y_test.iloc[:, i], y_test_pred_rf[:, i]):.4f}\")\n",
    "    print(f\"  R2: {r2_score(y_test.iloc[:, i], y_test_pred_rf[:, i]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68902de",
   "metadata": {},
   "source": [
    "### Enhanced Run (tuned hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae55fd5",
   "metadata": {},
   "source": [
    "#### First Stage: structure + regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f51a1721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best parameters found: {'regressor__model__estimator__max_depth': 10, 'regressor__model__estimator__max_features': 0.5, 'regressor__model__estimator__min_samples_leaf': 4}\n",
      "\n",
      "Random Forest Training Set Performance:\n",
      "\n",
      "item_count:\n",
      "  RMSE: 45.8082\n",
      "  MAE: 4.1017\n",
      "  R2: 0.5094\n",
      "\n",
      "order_count:\n",
      "  RMSE: 13.9589\n",
      "  MAE: 2.2475\n",
      "  R2: 0.5881\n",
      "\n",
      "Random Forest Test Set Performance:\n",
      "\n",
      "item_count:\n",
      "  RMSE: 45.0272\n",
      "  MAE: 4.1390\n",
      "  R2: 0.3523\n",
      "\n",
      "order_count:\n",
      "  RMSE: 16.8069\n",
      "  MAE: 2.6346\n",
      "  R2: 0.2596\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', MultiOutputRegressor(RandomForestRegressor(n_jobs=-1, random_state=42)))\n",
    "])\n",
    "\n",
    "random_forest_model = TransformedTargetRegressor(\n",
    "    regressor=pipeline,\n",
    "    func=np.log1p,\n",
    "    inverse_func=np.expm1\n",
    ")\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    estimator=random_forest_model,\n",
    "    param_grid = {\n",
    "        'regressor__model__estimator__max_depth': [10, 20],\n",
    "        'regressor__model__estimator__min_samples_leaf': [2, 4],\n",
    "        'regressor__model__estimator__max_features': ['sqrt', 0.5],\n",
    "    },\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=TimeSeriesSplit(n_splits=5),\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "gs.fit(x_train, y_train)\n",
    "print(f\"Best parameters found: {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a790d987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Best parameters found: {'regressor__model__estimator__max_depth': 15, 'regressor__model__estimator__max_features': 0.5, 'regressor__model__estimator__min_samples_leaf': 5}\n"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(\n",
    "    estimator=random_forest_model,\n",
    "    param_grid = {\n",
    "        'regressor__model__estimator__max_depth': [5, 10, 15],\n",
    "        'regressor__model__estimator__min_samples_leaf': [3, 4, 5],\n",
    "        'regressor__model__estimator__max_features': [0.5, 'log2'],\n",
    "    },\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=TimeSeriesSplit(n_splits=5),\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "gs.fit(x_train, y_train)\n",
    "print(f\"Best parameters found: {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f56f204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best parameters found: {'regressor__model__estimator__max_depth': 10, 'regressor__model__estimator__min_samples_leaf': 7}\n"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(\n",
    "    estimator=random_forest_model,\n",
    "    param_grid = {\n",
    "        'regressor__model__estimator__max_depth': [10, 15, 20, 25],\n",
    "        'regressor__model__estimator__min_samples_leaf': [4, 5, 6, 7]\n",
    "    },\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=TimeSeriesSplit(n_splits=5),\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "gs.fit(x_train, y_train)\n",
    "print(f\"Best parameters found: {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b1a1ab",
   "metadata": {},
   "source": [
    "#### Second: stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a29d7507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best parameters found: {'regressor__model__estimator__bootstrap': True, 'regressor__model__estimator__n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "gs2 = GridSearchCV(\n",
    "    estimator=random_forest_model,\n",
    "    param_grid = {\n",
    "        'regressor__model__estimator__n_estimators': [100, 200, 400],\n",
    "        'regressor__model__estimator__bootstrap': [True, False],\n",
    "    },\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=TimeSeriesSplit(n_splits=5),\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "gs2.fit(x_train, y_train)\n",
    "print(f\"Best parameters found: {gs2.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "103d9171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best parameters found: {'regressor__model__estimator__bootstrap': True, 'regressor__model__estimator__n_estimators': 600}\n"
     ]
    }
   ],
   "source": [
    "gs2 = GridSearchCV(\n",
    "    estimator=random_forest_model,\n",
    "    param_grid = {\n",
    "        'regressor__model__estimator__n_estimators': [400, 500, 600],\n",
    "        'regressor__model__estimator__bootstrap': [True, False],\n",
    "    },\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=TimeSeriesSplit(n_splits=5),\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "gs2.fit(x_train, y_train)\n",
    "print(f\"Best parameters found: {gs2.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d921d9bc",
   "metadata": {},
   "source": [
    "### Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "192a1d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Training Set Performance:\n",
      "\n",
      "item_count:\n",
      "  RMSE: 42.0605\n",
      "  MAE: 3.8744\n",
      "  R2: 0.5496\n",
      "\n",
      "order_count:\n",
      "  RMSE: 12.8727\n",
      "  MAE: 2.1199\n",
      "  R2: 0.6201\n",
      "\n",
      "Random Forest Test Set Performance:\n",
      "\n",
      "item_count:\n",
      "  RMSE: 43.9296\n",
      "  MAE: 4.1022\n",
      "  R2: 0.3681\n",
      "\n",
      "order_count:\n",
      "  RMSE: 16.7582\n",
      "  MAE: 2.6258\n",
      "  R2: 0.2618\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', MultiOutputRegressor(RandomForestRegressor(\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        max_depth=12,\n",
    "        min_samples_leaf=7,\n",
    "        max_features=0.5,\n",
    "        n_estimators=600,\n",
    "        bootstrap=True\n",
    "    )))\n",
    "])\n",
    "\n",
    "best_model = TransformedTargetRegressor(\n",
    "    regressor=pipeline,\n",
    "    func=np.log1p,\n",
    "    inverse_func=np.expm1\n",
    ")\n",
    "\n",
    "best_model.fit(x_train, y_train)\n",
    "\n",
    "y_train_pred_best = best_model.predict(x_train)\n",
    "y_test_pred_best = best_model.predict(x_test)\n",
    "\n",
    "# Evaluate on training set\n",
    "print(\"\\nRandom Forest Training Set Performance:\")\n",
    "for i, target in enumerate(target_features):\n",
    "    print(f\"\\n{target}:\")\n",
    "    print(f\"  RMSE: {mean_squared_error(y_train.iloc[:, i], y_train_pred_best[:, i]):.4f}\")\n",
    "    print(f\"  MAE: {mean_absolute_error(y_train.iloc[:, i], y_train_pred_best[:, i]):.4f}\")\n",
    "    print(f\"  R2: {r2_score(y_train.iloc[:, i], y_train_pred_best[:, i]):.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\nRandom Forest Test Set Performance:\")\n",
    "for i, target in enumerate(target_features):\n",
    "    print(f\"\\n{target}:\")\n",
    "    print(f\"  RMSE: {mean_squared_error(y_test.iloc[:, i], y_test_pred_best[:, i]):.4f}\")\n",
    "    print(f\"  MAE: {mean_absolute_error(y_test.iloc[:, i], y_test_pred_best[:, i]):.4f}\")\n",
    "    print(f\"  R2: {r2_score(y_test.iloc[:, i], y_test_pred_best[:, i]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84e0eb1",
   "metadata": {},
   "source": [
    "## Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "17889a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/models/rf_model_metadata.json']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = {\n",
    "    'python_version': sys.version,\n",
    "    'sklearn_version': sys.modules['sklearn'].__version__,\n",
    "    'numpy_version': sys.modules['numpy'].__version__,\n",
    "    'model_type': 'RandomForestRegressor',\n",
    "    'preprocessing': {\n",
    "        'scaled_features': scale_features,\n",
    "        'imputation_strategies': {\n",
    "            'type_id': 'mode (-1 for unknown)',\n",
    "            'waiting_time': 'median',\n",
    "            'rating': 'median',\n",
    "            'delivery': 'fill 0',\n",
    "            'accepting_orders': 'fill 0'\n",
    "        }\n",
    "    },\n",
    "    'hyperparameters': {\n",
    "        'max_depth': 12,\n",
    "        'min_samples_leaf': 7,\n",
    "        'max_features': 0.5,\n",
    "        'n_estimators': 600,\n",
    "        'bootstrap': True\n",
    "    },\n",
    "    'training_size': len(x_train),\n",
    "    'test_size': len(x_test)\n",
    "}\n",
    "\n",
    "joblib.dump(best_model, '../data/models/rf_model.joblib')\n",
    "joblib.dump(metadata, '../data/models/rf_model_metadata.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2ec8a5",
   "metadata": {},
   "source": [
    "## DONE!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deloitte",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
